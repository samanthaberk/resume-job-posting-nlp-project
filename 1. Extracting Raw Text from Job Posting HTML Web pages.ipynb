{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Extracting Raw Text from HTML {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:**\n",
    "Extract relevant sections of the job posting webpages for similarity comparison with our resume and analysis of skills missing from our resume.\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1. Examine some HTML pages manually by opening them in a browser and inspecting the HTML elements (e.g. ctrl+shift+i in many browsers or right click on the page and choose “inspect”). Determine which sections should be extracted and stored.\n",
    "2. Load all webpages into Python as text in a list using any method.\n",
    "3. Store the webpage sections identified in step 1 into a pandas DataFrame with sensible column names.\n",
    "    - Examine some of the data in the DataFrame to make sure the data extraction worked as we expect.\n",
    "    - Save the DataFrame to disk so we can load it at a later time for future parts of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspecting HTML pages {-}\n",
    "After opening some job postings in a browser and inspecting the HTML of the page (with ctrl+shift+i or right-clicking the page and choosing 'inspect'), we can see that typically, required skills are contained in bullet points.  Sometimes other information is contained in bullet points as well.  With more advanced webpage parsing (e.g. searching for the 'Required Skills' string or something similar) we could potentially limit our bullet points to only those with required skills.  However, we won't take those extra steps here since that level of data cleaning can be an entire project on its own.\n",
    "\n",
    "The bullet points with skill requirements are 'ul' HTML tags with 'li' tags inside them.\n",
    "\n",
    "We can also see the title of the posting is contained within a 'title' html tag.  The entire text of the post is contained within the 'body' tag.  So our plan is to separately store the 'body', 'title', and 'li' tags in separate pandas DataFrame columns.\n",
    "\n",
    "The HTML file used here was 0a3e1fcd0264cf9a_fccid.html, which came up first in the file browser when the files were sorted by name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![inspecting a job posting](images/inspect_a_page.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load webpages into Python {-}\n",
    "Next, we get the list of files to be opened and see how many there are.  Then we read in the files into a list.  We will look at some of the data we read in to make sure it looks ok.\n",
    "\n",
    "Usually it's best to group your library imports in a cell or two at the beginning of your notebook, to keep it organized.  Imports should be grouped as per PEP8: https://www.python.org/dev/peps/pep-0008/#imports.  We'll import our libraries needed for each section (step) at the top of that section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the files in the html directory\n",
    "files = glob.glob('html_job_postings//*.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1337"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all HTML pages as text into a list -- one entry per HTML page\n",
    "html_content = []\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        html_content.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><head><title>Operations Insights and Impact Analyst, YouTube - San Bruno, CA</title></head>\\n<body><h2>Operations Insights and Impact Analyst, YouTube - San Bruno, CA</h2>\\n<p>Minimum qualifications:</p><ul>\\n<li>\\nBachelor\\'s degree in Data Science, Economics, Statistics, Business or Finance, or equivalent practical experience.</li>\\n<li>4 years of experience in operations analytics or business analytics.</li>\\n<li>Experience in using relational databases for SQL queries, database definition and schema design.</li>\\n<li>Experience with building and presenting operational dashboards.</li>\\n</ul><br/>\\n<p>Preferred qualifications:</p><ul>\\n<li>\\nExperience with running operations management processes (sales and operations planning, demand/supply planning).</li>\\n<li>Experience in strategy and consulting.</li>\\n<li>Experience in marketing analytics, ROI, financial modeling and statistical analysis.</li>\\n<li>Developed business fundamentals acumen and knowledge of video advertising business models.</li>\\n<li>Ability to work independently on project deliverables in a fast-paced, ambiguous environment while working well in cross-functional teams. Developed project management skills.</li>\\n<li>Excellent oral and written communication, interpersonal and analytical skills.</li>\\n</ul><div><h2 class=\"jobSectionHeader\"><b>About the job</b></h2><p>\\nThe YouTube Insights, Impact &amp; Tools team supports the YouTube business and operations teams with data infrastructure, tools, and analytical support. Our charter is to help our internal partners run their businesses by providing rigorous, insightful data and by building solutions and services which transform how the YouTube business teams work.</p>\\n<p>As an Analyst, you\\'ll help to identify top operational challenges, work with diverse cross-functional teams and guide business leadership on optimizing the effectiveness and efficiency of our partner-facing operations. You\\'ll support business leaders with insightful, actionable analysis and by creating the tracking and impact measurement behind the business.</p><p>\\nAt YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.</p></div><div><h2 class=\"jobSectionHeader\"><b>\\nResponsibilities</b></h2><ul>\\n<li>Identify opportunities to improve the operational performance for the Content Operations teams through insightful analysis of business metrics.</li>\\n<li>Act as a thought leader in the creation of planning, strategy and key performance indicator (KPI) development for Operations teams. Make strategic and operational recommendations to achieve targets and operational excellence.</li>\\n<li>Track the progress of reaching team KPIs and success metrics.</li>\\n<li>Articulate and prioritize operations-related requirements for Content Tools and Business Data teams.</li>\\n<li>Understand team workflows to drive operational improvements and achieve industry-leading support. Train stakeholders on tools and own data accuracy for relationship mapping.</li>\\n</ul></div>At Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google\\'s EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.</body>\\n</html>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect the first entry to make sure it looks ok\n",
    "html_content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Store webpage sections into a pandas DataFrame {-}\n",
    "Now we are going to parse the HTML into sections -- Title, Body, and bullets points ('li' tags which typically hold required skills) and store these in a DataFrame.  These will be stored in a dictionary with lists as values, and then converted to a DataFrame.\n",
    "\n",
    "First, we prototype the code to extract the content from the page.  Then we'll incorporate it in a function which takes in all html pages and returns a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a dictionary to store data, which can easily be converted to a pandas DataFrame\n",
    "html_sections = []\n",
    "html_dict = {}\n",
    "for key in ['title', 'body', 'bullets']:\n",
    "    html_dict[key] = []\n",
    "\n",
    "# use the first page for prototyping the code\n",
    "first_page = html_content[0]\n",
    "# converting the text to a beautifulsoup object makes it easily searchable\n",
    "soup = bs(first_page, 'lxml')\n",
    "title = soup.find('title').text\n",
    "body = soup.find('body').text\n",
    "bullets = soup.find_all('li')\n",
    "html_dict['title'].append(title)\n",
    "html_dict['body'].append(body)\n",
    "# remove extra leading and trailing whitespace with strip()\n",
    "html_dict['bullets'].append([b.text.strip() for b in bullets])\n",
    "\n",
    "df = pd.DataFrame(data=html_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>bullets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Operations Insights and Impact Analyst, YouTub...</td>\n",
       "      <td>Operations Insights and Impact Analyst, YouTub...</td>\n",
       "      <td>[Bachelor's degree in Data Science, Economics,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Operations Insights and Impact Analyst, YouTub...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Operations Insights and Impact Analyst, YouTub...   \n",
       "\n",
       "                                             bullets  \n",
       "0  [Bachelor's degree in Data Science, Economics,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best to always write some documentation for your functions as shown here in the triple quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_content(html_pages):\n",
    "    \"\"\"\n",
    "    Extracts title, body, and list items (bullets) from HTML job postigs.\n",
    "    Returns a pandas dataframe with separate columns for title, body, and bullet items.S\n",
    "    \"\"\"\n",
    "    html_sections = []\n",
    "    html_dict = {}\n",
    "    for key in ['title', 'body', 'bullets']:\n",
    "        html_dict[key] = []\n",
    "\n",
    "    for html in html_content:\n",
    "        soup = bs(html, 'lxml')\n",
    "        title = soup.find('title').text\n",
    "        body = soup.find('body').text\n",
    "        bullets = soup.find_all('li')\n",
    "        html_dict['title'].append(title)\n",
    "        html_dict['body'].append(body)\n",
    "        # remove extra leading and trailing whitespace with strip()\n",
    "        html_dict['bullets'].append([b.text.strip() for b in bullets])\n",
    "    \n",
    "    df = pd.DataFrame(html_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_html_content(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>bullets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Operations Insights and Impact Analyst, YouTub...</td>\n",
       "      <td>Operations Insights and Impact Analyst, YouTub...</td>\n",
       "      <td>[Bachelor's degree in Data Science, Economics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mathematical and Statistical Scientist* - Char...</td>\n",
       "      <td>Mathematical and Statistical Scientist* - Char...</td>\n",
       "      <td>[BS in Statistics, Mathematics, or a related f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Lead - Chicago, IL</td>\n",
       "      <td>Data Science Lead - Chicago, IL\\nWho we are:\\n...</td>\n",
       "      <td>[Lead the development, implementation and opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Developer 3 - Redwood City, CA 94065</td>\n",
       "      <td>Software Developer 3 - Redwood City, CA 94065\\...</td>\n",
       "      <td>[3+ years of Java, Go, or Python frontend and/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Orange, CA</td>\n",
       "      <td>Data Scientist - Orange, CA\\nRole Summary / Pu...</td>\n",
       "      <td>[PhD in Industrial Engineering, computer scien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Operations Insights and Impact Analyst, YouTub...   \n",
       "1  Mathematical and Statistical Scientist* - Char...   \n",
       "2                    Data Science Lead - Chicago, IL   \n",
       "3      Software Developer 3 - Redwood City, CA 94065   \n",
       "4                        Data Scientist - Orange, CA   \n",
       "\n",
       "                                                body  \\\n",
       "0  Operations Insights and Impact Analyst, YouTub...   \n",
       "1  Mathematical and Statistical Scientist* - Char...   \n",
       "2  Data Science Lead - Chicago, IL\\nWho we are:\\n...   \n",
       "3  Software Developer 3 - Redwood City, CA 94065\\...   \n",
       "4  Data Scientist - Orange, CA\\nRole Summary / Pu...   \n",
       "\n",
       "                                             bullets  \n",
       "0  [Bachelor's degree in Data Science, Economics,...  \n",
       "1  [BS in Statistics, Mathematics, or a related f...  \n",
       "2  [Lead the development, implementation and opti...  \n",
       "3  [3+ years of Java, Go, or Python frontend and/...  \n",
       "4  [PhD in Industrial Engineering, computer scien...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1337, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas DataFrames enables several convenience functions, such as drop_duplicates.  However, we can't drop dupes with columns of lists, so we have to convert the bullets column (which are lists) to tuples first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bullets'] = df['bullets'].apply(tuple, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1328, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are a few duplicates in there which we have now removed.  Now we have our parsed text data ready for more analysis!\n",
    "\n",
    "The last step is to save the DataFrame to disk for future steps.  There are [several methods](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) for storing data, but we will keep it simple with a pickle file (even though it may not have the best performance for many use cases).  Using a CSV file would normally work, but since our 'bullets' column is a list, we need to do some [extra steps](https://stackoverflow.com/q/23111990/4549682) in order to get a list back when reading a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('step1_df.pk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
